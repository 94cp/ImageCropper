//
//  ImageCropper.swift
//  ImageCropper
//
//  Created by chen p on 2018/11/21.
//  Copyright Â© 2018 chenp. All rights reserved.
//

import UIKit
#if canImport(Vision)
    import Vision
#else
    import CoreImage
#endif

extension NSObject: ImageCroppable {}
extension CGImage: ImageCroppable {}

/// å›¾ç‰‡è£å‰ªåè®®
public protocol ImageCroppable {}

/// è£å‰ªç±»å‹
///
/// - face: äººè„¸
/// - barcode: æ¡å½¢ç ã€äºŒç»´ç ç­‰
/// - text: æ–‡æœ¬
/// - rectangle: çŸ©å½¢
public enum DetectionType {
    case face
    case barcode
    case text
    case rectangle
}

/// è¯†åˆ«ç»“æœ
///
/// - success: æˆåŠŸ
/// - notFound: æ²¡æ‰¾åˆ°éœ€è¦è¯†åˆ«çš„ç±»å‹å›¾åƒ
/// - failure: å¤±è´¥
public enum ImageDetectResult<T> {
    case success([T])
    case notFound
    case failure(Error)
}

/// å›¾åƒè£å‰ªå·¥å…·ç±»
public struct ImageCropper<T> {
    let detectable: T
    init(_ detectable: T) {
        self.detectable = detectable
    }
}

public extension ImageCroppable {
    var detector: ImageCropper<Self> {
        return ImageCropper(self)
    }
}

// MARK: - ğŸ”¥CGImage è£å‰ªğŸ”¥
public extension ImageCropper where T: CGImage {
    
    /// è£å‰ªå‡ºCGImageå›¾ç‰‡æ–¹æ³•
    ///
    /// - Parameters:
    ///   - type: è£å‰ªç±»å‹
    ///   - completion: ç»“æœå›è°ƒ
    func crop(type: DetectionType, completion: @escaping (ImageDetectResult<CGImage>) -> Void) {
        if #available(iOS 11.0, *) {
            visionCrop(type: type, completion: completion)
        } else {
            coreImageCrop(type: type, completion: completion)
        }
    }
    
    @available(iOS 11.0, *)
    private func visionCrop(type: DetectionType, completion: @escaping (ImageDetectResult<CGImage>) -> Void) {
        // è®¾ç½®å›è°ƒ
        let completionHandle: VNRequestCompletionHandler = { request, error in
            guard error == nil else {
                completion(.failure(error!))
                return
            }
            
            let cropImages = request.results?.map({ result -> CGImage? in
                guard let detectedObj = result as? VNDetectedObjectObservation else { return nil }
                let image = self.cropImage(object: detectedObj)
                return image
            }).compactMap { $0 }
            
            guard let result = cropImages, result.count > 0 else {
                completion(.notFound)
                return
            }
            
            completion(.success(result))
        }
        
        // åˆ›å»ºè¯†åˆ«è¯·æ±‚
        let req = createVNImageRequest(type: type, completionHandle: completionHandle)
        
        do {
            try VNImageRequestHandler(cgImage: detectable, options: [:]).perform([req])
        } catch let error {
            completion(.failure(error))
        }
    }
    
    @available(iOS 11.0, *)
    private func createVNImageRequest(type: DetectionType, completionHandle: @escaping VNRequestCompletionHandler) -> VNImageBasedRequest {
        switch type {
        case .face:
            return VNDetectFaceRectanglesRequest(completionHandler: completionHandle)
        case .barcode:
            return VNDetectBarcodesRequest(completionHandler: completionHandle)
        case .text:
            return VNDetectTextRectanglesRequest(completionHandler: completionHandle)
        case .rectangle:
            return VNDetectRectanglesRequest(completionHandler: completionHandle)
        }
    }
    
    private func coreImageCrop(type: DetectionType, completion: @escaping (ImageDetectResult<CGImage>) -> Void) {
        let ciImage = CIImage(cgImage: detectable)
        // è¯†åˆ«ç»“æœç²¾åº¦
        let accuracy = [CIDetectorAccuracy: CIDetectorAccuracyHigh]
        // è®¾ç½®è¯†åˆ«ç±»å‹
        let detector = CIDetector(ofType: getDetectorType(type: type), context: nil, options: accuracy)
        // è¯†åˆ«ç»“æœ
        let results = detector?.features(in: ciImage)
        
        let ciImageSize = ciImage.extent.size
        var transform = CGAffineTransform(scaleX: 1, y: -1)
        transform = transform.translatedBy(x: 0, y: -ciImageSize.height)
        
        let cropImages = results?.map({ (result) -> CGImage? in
            guard let detectedObj = result as? CIFaceFeature else { return nil }
            let image = self.cropImage(bounds: detectedObj.bounds.applying(transform), ciImageSize: ciImageSize)
            return image
        }).compactMap { $0 }
        
        guard let result = cropImages, result.count > 0 else {
            completion(.notFound)
            return
        }
        
        completion(.success(result))
    }
    
    private func getDetectorType(type: DetectionType) -> String {
        switch type {
        case .face:
            return CIDetectorTypeFace
        case .barcode:
            return CIDetectorTypeQRCode
        case .text:
            return CIDetectorTypeText
        case .rectangle:
            return CIDetectorTypeRectangle
        }
    }
    
    /// Vision å›¾ç‰‡è£å‰ªæ–¹æ³•
    @available(iOS 11.0, *)
    private func cropImage(object: VNDetectedObjectObservation) -> CGImage? {
        let width = object.boundingBox.width * CGFloat(detectable.width)
        let height = object.boundingBox.height * CGFloat(detectable.height)
        let x = object.boundingBox.origin.x * CGFloat(detectable.width)
        let y = (1 - object.boundingBox.origin.y) * CGFloat(detectable.height) - height
        
        let croppingRect = CGRect(x: x, y: y, width: width, height: height)
        
        let image = self.detectable.cropping(to: croppingRect)
        return image
    }
    
    /// CoreImage å›¾ç‰‡è£å‰ªæ–¹æ³•
    private func cropImage(bounds: CGRect, ciImageSize: CGSize) -> CGImage? {
        var croppingRect = bounds
        
        let scaleX = CGFloat(detectable.width) / ciImageSize.width
        let scaleY = CGFloat(detectable.height) / ciImageSize.height
        let offsetX = (CGFloat(detectable.width) - ciImageSize.width * scaleX) / 2
        let offsetY = (CGFloat(detectable.height) - ciImageSize.height * scaleY) / 2

        croppingRect = croppingRect.applying(CGAffineTransform(scaleX: scaleX, y: scaleY))
        croppingRect.origin.x += offsetX
        croppingRect.origin.y += offsetY

        let image = self.detectable.cropping(to: croppingRect)
        return image
    }
}

// MARK: - ğŸ”¥UIImage è£å‰ªğŸ”¥
public extension ImageCropper where T: UIImage {
    
    /// è£å‰ªå‡ºUIImageå›¾ç‰‡æ–¹æ³•
    ///
    /// - Parameters:
    ///   - type: è£å‰ªç±»å‹
    ///   - completion: ç»“æœå›è°ƒ
    func crop(type: DetectionType, completion: @escaping (ImageDetectResult<UIImage>) -> Void) {
        detectable.cgImage!.detector.crop(type: type) { result in
            switch result {
            case .success(let cgImages):
                let faces = cgImages.map { cgImage -> UIImage in
                    return UIImage(cgImage: cgImage)
                }
                completion(.success(faces))
            case .notFound:
                completion(.notFound)
            case .failure(let error):
                completion(.failure(error))
            }
        }
    }
}
